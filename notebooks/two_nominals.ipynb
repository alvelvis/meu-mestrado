{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"estrutura_ud.py\"):\n",
    "    ! wget https://raw.githubusercontent.com/alvelvis/ACDC-UD/master/estrutura_ud.py\n",
    "import estrutura_ud\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "build: 10.978663682937622"
     ]
    }
   ],
   "source": [
    "file = \"../Bosque/bosque-workbench.conllu\"\n",
    "#file = \"../Petroles_v2/Petroles_2.conllu\"\n",
    "corpus = estrutura_ud.Corpus()\n",
    "corpus.load(file)\n",
    "\n",
    "for i in range(2):\n",
    "    for sentence in corpus.sentences.values():\n",
    "        if sentence.sent_id not in [\n",
    "            \"1-20140905-TESEDSC_0_resumo-11\",\n",
    "            \"32-20141110-MONOGRAFIA_0_resumo-19\",\n",
    "            \"36-20140327-TESEMSC_0_resumo-6\",\n",
    "            \"51-20140924-MONOGRAFIA_0_resumo-1\",\n",
    "            \"6-20140908-MONOGRAFIA_0_intro-53\",\n",
    "            '105-20151215-MONOGRAFIA_0_resumo-8',\n",
    "            \"32-20141110-MONOGRAFIA_0_resumo-13\",\n",
    "            \"20-20140904-TESEDSC_0-59\",\n",
    "            \"20-20140904-TESEDSC_0-66\",\n",
    "            \"19-20140916-TESEDSC_0_resumo-9\",\n",
    "            \"CF47-3\",\n",
    "            \"CF51-2\",\n",
    "            \"CF68-2\",\n",
    "            \"CF122-3\",\n",
    "            \"CF124-3\",\n",
    "            \"CF151-31\",\n",
    "            \"CF423-5\",\n",
    "            \"CF476-4\",\n",
    "            \"CF479-1\",\n",
    "            \"CF602-4\",\n",
    "            \"CP161-4\",\n",
    "            \"CF288-7\",\n",
    "            \"CP782-2\"\n",
    "        ]:\n",
    "            tokens = sentence.tokens\n",
    "            for token in tokens:\n",
    "\n",
    "                if not '-' in token.id and token.deprel not in [\"appos:parataxis\", \"compound\", \"flat:foreign\", \"orphan\", \"flat\", \"fixed\", \"orphan\"]:\n",
    "                    has_cc = False\n",
    "                    has_colon = False\n",
    "                    has_comma = False\n",
    "                    has_parenthesis = False\n",
    "                    has_pronrel = False\n",
    "                    for _token in tokens:\n",
    "                        #if _token.word in [\",\", \"-\", \"–\", \";\", \"--\", \"...\", \":\"] and _token.dephead == token.head_token.id and token.deprel == \"appos\" and token != _token:\n",
    "                            #_token.dephead = token.id\n",
    "                        if _token.dephead == token.id:\n",
    "                            if _token.deprel == \"cc\":\n",
    "                                has_cc = True\n",
    "                            if _token.word in [\",\", \"-\", \"–\", \";\", \"--\", \"...\"]:\n",
    "                                has_comma = True\n",
    "                            if _token.word in [\"(\", \"[\"]:\n",
    "                                has_parenthesis = True\n",
    "                            if \"PronType=Rel\" in _token.feats:\n",
    "                                has_pronrel = True\n",
    "                        if _token.dephead == token.id:\n",
    "                            if _token.word == \":\":\n",
    "                                has_colon = True\n",
    "\n",
    "                    if token.word in [\"um\", \"uma\", \"uns\", \"umas\"] and token.next_token.word == \"de\":\n",
    "                        if sentence.sent_id not in [\"CP659-1\"]:\n",
    "                            token.upos = \"PRON\"\n",
    "                            token.lemma = \"um\"\n",
    "                            token.feats = \"Gender={}|Number={}|PronType=Ind\".format('Fem' if 'a' in token.word.lower() else \"Masc\", \"Plur\" if 's' in token.word.lower() else \"Sing\")\n",
    "\n",
    "                    if token.upos in [\"PRON\", \"NOUN\"] and token.head_token.upos == \"NOUN\" and int(token.id) > int(token.head_token.id):\n",
    "                        if not any([has_comma, has_cc, has_colon, has_parenthesis, has_pronrel]) and token.deprel not in [\"nsubj\", \"acl\"]:\n",
    "                            token.deprel = \"nmod\"\n",
    "\n",
    "                    if token.upos == \"NUM\" and token.head_token.upos == \"NOUN\" and int(token.id) > int(token.head_token.id):\n",
    "                        if not any([has_comma, has_cc, has_colon, has_parenthesis]):\n",
    "                            token.deprel = \"nummod\"\n",
    "\n",
    "                    if token.upos == \"PROPN\" and token.head_token.upos in [\"NOUN\"] and int(token.id) > int(token.head_token.id):\n",
    "                        if sentence.sent_id not in [\n",
    "                            \"CF473-3\",\n",
    "                            \"CF504-1\",\n",
    "                            \"CF536-7\",\n",
    "                            \"CF666-5\",\n",
    "                            \"CF931-3\",\n",
    "                            \"CP233-6\",\n",
    "                            \"CP791-7\"\n",
    "                            ]:\n",
    "                            if not any([has_colon, has_comma, has_parenthesis, has_cc, has_pronrel]) and token.deprel != \"nsubj\":\n",
    "                                if token.previous_token.word in [\",\", \":\", \"--\", \";\"] and token.deprel in [\"appos\", \"conj\"]:\n",
    "                                    if int(token.head_token.id) > int(token.previous_token.id):\n",
    "                                        token.previous_token.dephead = token.head_token.id\n",
    "                                    else:\n",
    "                                        token.previous_token.dephead = token.id\n",
    "                                elif token.previous_token.previous_token.word in [\",\", \":\", \"--\", \";\"] and token.deprel in [\"appos\", \"conj\"] and int(token.previous_token.previous_token.dephead) < int(token.previous_token.previous_token.id):\n",
    "                                    if int(token.head_token.id) > int(token.previous_token.previous_token.id):\n",
    "                                        token.previous_token.previous_token.dephead = token.head_token.id\n",
    "                                    else:\n",
    "                                        token.previous_token.previous_token.dephead = token.id\n",
    "                                elif token.previous_token.id != \"1\" and token.previous_token.previous_token.previous_token.word in [\",\", \":\", \"--\", \";\"] and token.deprel in [\"appos\", \"conj\"] and int(token.previous_token.previous_token.previous_token.dephead) < int(token.previous_token.previous_token.previous_token.id):\n",
    "                                    if int(token.head_token.id) > int(token.previous_token.previous_token.previous_token.id):\n",
    "                                        token.previous_token.previous_token.previous_token.dephead = token.head_token.id\n",
    "                                    else:\n",
    "                                        token.previous_token.previous_token.previous_token.dephead = token.id\n",
    "                                else:\n",
    "                                    token.deprel = \"nmod\"\n",
    "\n",
    "                    if token.upos == \"PROPN\" and token.head_token.upos == \"PROPN\" and int(token.id) > int(token.head_token.id):\n",
    "                        if sentence.sent_id not in [\n",
    "                            \"CF178-2\",\n",
    "                            \"CF183-1\",\n",
    "                            \"CF248-1\",\n",
    "                            \"CF288-5\",\n",
    "                            \"CF298-4\",\n",
    "                            \"CF307-3\",\n",
    "                            \"CF308-4\",\n",
    "                            \"CF329-3\",\n",
    "                            \"CF380-3\",\n",
    "                            \"CF384-5\",\n",
    "                            \"CF409-4\"\n",
    "                            ]:\n",
    "                            if not any([has_cc, has_comma, has_parenthesis]):\n",
    "                                token.deprel = \"flat:name\"\n",
    "                                if token.head_token == \"flat:name\":\n",
    "                                    token.dephead = token.head_token.dephead\n",
    "                                #for _token in tokens:\n",
    "                                    #if _token.dephead == token.id:\n",
    "                                        #if _token.upos in [\"ADP\", \"DET\", \"PUNCT\", \"CCONJ\"] and int(_token.id) > int(token.head_token.id): #or _token.word in [\"--\"]:\n",
    "                                        #_token.dephead = token.dephead\n",
    "                                for _token in tokens:\n",
    "                                    if (_token.dephead == token.head_token.id or _token.dephead == token.id) and int(_token.id) > int(token.head_token.id) and int(_token.id) < int(token.id):\n",
    "                                        if _token.word not in [\"(\", \")\", \"«\", \"»\"]:\n",
    "                                            _token.deprel = \"flat:name\"\n",
    "                                        else:\n",
    "                                            break\n",
    "\n",
    "                    if token.head_token.deprel == \"flat:name\" and token.word not in [\"(\", \")\"]:# and token.upos in [\"ADP\", \"DET\", \"PUNCT\", \"CCONJ\"]:\n",
    "                        token.dephead = token.head_token.dephead# if token.head_token.head_token.deprel != \"flat:name\" else token.head_token.head_token.dephead\n",
    "                        #if not any([has_cc, has_comma]):\n",
    "                        #token.deprel = \"flat:name\"\n",
    "                    \n",
    "\n",
    "corpus.save(\"teste.conllu\")\n",
    "os.system(\"meld --diff {} teste.conllu\".format(file))\n",
    "os.remove(\"teste.conllu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}